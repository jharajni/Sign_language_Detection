{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0447fc-cd45-4062-8281-b4da76750cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QPushButton, QLabel, QFileDialog, QMessageBox\n",
    "from PyQt5.QtGui import QPixmap, QImage, QFont\n",
    "from PyQt5.QtCore import QTimer\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9fafd69-41dc-494a-8532-fc60ea2245ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class SignLanguageApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super(SignLanguageApp, self).__init__()\n",
    "        self.setWindowTitle(\"Sign Language Detection\")\n",
    "        self.setGeometry(100, 100, 800, 600)\n",
    "\n",
    "        #### Styling background \n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QMainWindow {\n",
    "                background: qlineargradient(\n",
    "                    x1: 0, y1: 0, x2: 1, y2: 1,\n",
    "                    stop: 0 #f7b733, stop: 1 #fc4a1a\n",
    "                );\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "        self.title_label = QLabel(\"Sign Language Detection\", self)\n",
    "        self.title_label.setGeometry(100, 10, 600, 60)\n",
    "        self.title_label.setStyleSheet(\"\"\"\n",
    "            QLabel {\n",
    "                color: #ffffff;\n",
    "                font-size: 28px;\n",
    "                font-weight: bold;\n",
    "                text-align: center;\n",
    "                text-shadow: 2px 2px 4px #000000;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.title_label.setFont(QFont(\"Arial\", 28))\n",
    "\n",
    "        #### Creating and styling upload button  \n",
    "        self.upload_button = QPushButton(\"Upload Image\", self)\n",
    "        self.upload_button.setGeometry(50, 80, 220, 50)\n",
    "        self.upload_button.setStyleSheet(\"\"\"\n",
    "            QPushButton {\n",
    "                background-color: #FF6347;\n",
    "                color: white;\n",
    "                font-size: 16px;\n",
    "                border-radius: 10px;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background-color: #FF4500;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.upload_button.clicked.connect(self.upload_image)\n",
    "\n",
    "        #### Creating real-time detection button \n",
    "        self.video_button = QPushButton(\"Real-time Detection\", self)\n",
    "        self.video_button.setGeometry(300, 80, 220, 50)\n",
    "        self.video_button.setStyleSheet(\"\"\"\n",
    "            QPushButton {\n",
    "                background-color: #4682B4;\n",
    "                color: white;\n",
    "                font-size: 16px;\n",
    "                border-radius: 10px;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background-color: #4169E1;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.video_button.clicked.connect(self.start_real_time_detection)\n",
    "\n",
    "        self.image_label = QLabel(self)\n",
    "        self.image_label.setGeometry(50, 150, 640, 400)\n",
    "        self.image_label.setStyleSheet(\"\"\"\n",
    "            QLabel {\n",
    "                background-color: #ffffff;\n",
    "                border: 2px solid #d3d3d3;\n",
    "                border-radius: 15px;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.image_label.setScaledContents(True)\n",
    "\n",
    "        #### styling prediction label\n",
    "        self.prediction_label = QLabel(\"Prediction: \", self)\n",
    "        self.prediction_label.setGeometry(50, 560, 700, 40)\n",
    "        self.prediction_label.setStyleSheet(\"color: #ffffff; font-size: 20px; font-weight: bold;\")\n",
    "        self.prediction_label.setFont(QFont(\"Arial\", 20))\n",
    "\n",
    "        #### here we will load the traines model\n",
    "        self.model = load_model('Sign_Language_CNN_Model.keras')\n",
    "        self.class_names = ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', \n",
    "                            'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', \n",
    "                            'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'best of luck', 'i love you', 'space']\n",
    "\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.cap = None\n",
    "\n",
    "    def upload_image(self):\n",
    "        \"\"\"Opens a file dialog to upload an image and display it on the GUI.\"\"\"\n",
    "        options = QFileDialog.Options()\n",
    "        file_path, _ = QFileDialog.getOpenFileName(self, \"Select Image\", \"\", \"Image Files (*.png *.jpg *.jpeg)\", options=options)\n",
    "        \n",
    "        if file_path:\n",
    "            pixmap = QPixmap(file_path)\n",
    "            scaled_pixmap = pixmap.scaled(self.image_label.width(), self.image_label.height(), aspectRatioMode=1)\n",
    "            self.image_label.setPixmap(scaled_pixmap)\n",
    "\n",
    "            #### For model  prediction we will preprocess the image\n",
    "            img = image.load_img(file_path, target_size=(64, 64))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = img_array / 255.0\n",
    "\n",
    "            prediction = self.model.predict(img_array)\n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "            predicted_label = self.class_names[predicted_class % len(self.class_names)]\n",
    "            self.prediction_label.setText(f\"Prediction: {predicted_label}\")\n",
    "        else:\n",
    "            QMessageBox.warning(self, \"Warning\", \"No image selected.\")\n",
    "\n",
    "    def start_real_time_detection(self):\n",
    "        \"\"\"Start the camera for real-time sign language detection.\"\"\"\n",
    "        self.cap = cv2.VideoCapture(0)  \n",
    "        if not self.cap.isOpened():\n",
    "            QMessageBox.warning(self, \"Warning\", \"Unable to access the camera.\")\n",
    "            return\n",
    "        \n",
    "        self.timer.start(30) \n",
    "\n",
    "    def update_frame(self):\n",
    "        \"\"\"Capture frames from the camera and predict sign language.\"\"\"\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            #### for displaying convert the frame to RGB \n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            #### For the model prediction we will preprocess the frame \n",
    "            img_array = cv2.resize(rgb_frame, (64, 64))  # Resize to (64, 64)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = img_array / 255.0\n",
    "\n",
    "            #### PREDICTION\n",
    "            prediction = self.model.predict(img_array)\n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "            predicted_label = self.class_names[predicted_class % len(self.class_names)]\n",
    "            self.prediction_label.setText(f\"Prediction: {predicted_label}\")\n",
    "\n",
    "            #### Displaying the video feed\n",
    "            h, w, ch = rgb_frame.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            self.image_label.setPixmap(QPixmap.fromImage(qt_image))\n",
    "        else:\n",
    "            self.timer.stop()\n",
    "            self.cap.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    window = SignLanguageApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
